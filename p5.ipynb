{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRACTICA 5 FILTROS 😁 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Filtro Modo Hamburguesas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks.python import BaseOptions\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "# Cargar imagen del emoji de hamburguesa y del corazon\n",
    "burger_img = cv2.imread('images/burger_emoji.png', cv2.IMREAD_UNCHANGED)\n",
    "heart_img = cv2.imread('images/heart_emoji.png', cv2.IMREAD_UNCHANGED)\n",
    "hat_img = cv2.imread('images/hat_img.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "burger_positions = []\n",
    "\n",
    "def draw_burgers(distance, lip_top, frame):\n",
    "    frame_height, frame_width = frame.shape[0], frame.shape[1]\n",
    "    \n",
    "    if distance > 60:  # Umbral\n",
    "        burger_resized = cv2.resize(burger_img, (50, 50))\n",
    "        burger_width, burger_height = burger_resized.shape[1], burger_resized.shape[0]\n",
    "\n",
    "        # Generar nuevas hamburguesas en la parte derecha e izquierda de la cara\n",
    "        for i in range(5):  # Número de hamburguesas a mostrar\n",
    "            if i >= len(burger_positions):\n",
    "                center_x, center_y = frame_width // 2, frame_height // 2  # Coordenadas centrales del frame\n",
    "                # Inicializar la posición de las hamburguesas al estilo json\n",
    "                burger_positions.append({\n",
    "                    \"x\": center_x + (i - 2) * (burger_width + 20),\n",
    "                    \"y\": center_y - burger_height // 2,\n",
    "                    \"direction\": 1,                    # Dirección hacia abajo\n",
    "                    \"side\": \"right\"                    # Indicar que es del lado derecho\n",
    "                })\n",
    "                burger_positions.append({\n",
    "                    \"x\": lip_top[0] - 100 - (i * 80),  # Espaciado entre hamburguesas en el lado izquierdo\n",
    "                    \"y\": -burger_height,               # Comenzar desde la parte superior fuera de la vista\n",
    "                    \"direction\": 1,                    # Dirección hacia abajo\n",
    "                    \"side\": \"left\"                     # Indicar que es del lado izquierdo\n",
    "                })\n",
    "            \n",
    "            # Actualizamos la posición de las hamburguesas\n",
    "            for j in range(len(burger_positions)):\n",
    "                burger_positions[j][\"y\"] += burger_positions[j][\"direction\"] * 5  # Mover hacia abajo\n",
    "                if burger_positions[j][\"y\"] > frame_height: burger_positions[j][\"y\"] = -burger_height  # Volver a la parte superior\n",
    "\n",
    "                # Verificar que la hamburguesa no se salga del cuadro\n",
    "                x_offset, y_offset  = burger_positions[j][\"x\"], burger_positions[j][\"y\"]\n",
    "\n",
    "                if x_offset + burger_width <= frame_width and y_offset + burger_height <= frame_height:\n",
    "                    # Dibujar la hamburguesa en su nueva posición\n",
    "                    for c in range(0, 3):\n",
    "                        try:\n",
    "                            frame[y_offset:y_offset+burger_height, x_offset:x_offset+burger_width, c] = \\\n",
    "                                burger_resized[:, :, c] * (burger_resized[:, :, 3] / 255.0) + \\\n",
    "                                frame[y_offset:y_offset+burger_height, x_offset:x_offset+burger_width, c] * \\\n",
    "                                (1.0 - burger_resized[:, :, 3] / 255.0)\n",
    "                        except Exception as e:\n",
    "                            continue\n",
    "                            \n",
    "def apply_hat(frame, face_landmarks):\n",
    "    # Utilizamos los puntos 183 y 332 de la malla facial como referencia para la parte superior de la cabeza\n",
    "    head_top = (int(face_landmarks.landmark[183].x * frame.shape[1]), \n",
    "                int(face_landmarks.landmark[332].y * frame.shape[0]))\n",
    "\n",
    "    # Combinación de puntos (punto 183 y punto 332).\n",
    "    head_top_avg_y = int((face_landmarks.landmark[183].y + face_landmarks.landmark[332].y) * frame.shape[0] / 2)\n",
    "\n",
    "    x_offset = head_top[0] - hat_img.shape[1] // 2       # Centrado horizontalmente\n",
    "    y_offset = head_top_avg_y - (hat_img.shape[0] // 2)  # Ajuste hacia la parte superior de la cabeza\n",
    "    \n",
    "    # Constante de desplazamiento\n",
    "    y_offset -= 150\n",
    "\n",
    "    # Asegurarnos de que la gorra no quede fuera de la imagen\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    \n",
    "    # Evitar que x_offset se salga por la izquierda y que y_offset se salga por la parte superior\n",
    "    if x_offset < 0: x_offset = 0\n",
    "    if y_offset < 0: y_offset = 0\n",
    "\n",
    "    # Asegurarnos de que la gorra no se salga por la derecha ni por la parte inferior\n",
    "    if x_offset + hat_img.shape[1] > frame_width: x_offset = frame_width - hat_img.shape[1]\n",
    "\n",
    "    if y_offset + hat_img.shape[0] > frame_height: y_offset = frame_height - hat_img.shape[0]\n",
    "\n",
    "    # Verificar que la gorra está dentro de los límites del frame\n",
    "    if x_offset + hat_img.shape[1] <= frame_width and y_offset + hat_img.shape[0] <= frame_height:\n",
    "        # Obtener la región de interés (ROI) en el frame\n",
    "        roi = frame[y_offset:y_offset + hat_img.shape[0], x_offset:x_offset + hat_img.shape[1]]\n",
    "\n",
    "        # Asegurar que la gorra tiene un canal alfa para manejar la transparencia\n",
    "        for c in range(0, 3):\n",
    "            roi[:, :, c] = roi[:, :, c] * (1.0 - hat_img[:, :, 3] / 255.0) + \\\n",
    "                            hat_img[:, :, c] * (hat_img[:, :, 3] / 255.0)\n",
    "\n",
    "        # Colocar la gorra en el frame\n",
    "        frame[y_offset:y_offset + hat_img.shape[0], x_offset:x_offset + hat_img.shape[1]] = roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "def calculate_distance(p1, p2):\n",
    "    # Calcular distancia euclidiana entre dos puntos (p1 y p2 son tuplas (x, y))\n",
    "    return np.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
    "           \n",
    "# Función para obtener las coordenadas de los puntos clave de la malla facial\n",
    "def process_frame(frame, face_mesh, points, mode):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    keypoints = []  # Lista para guardar las coordenadas de los puntos clave\n",
    "\n",
    "    if results.multi_face_landmarks is not None:\n",
    "        for face_landmarks in results.multi_face_landmarks:       \n",
    "            # Dibujar y guardar los puntos específicos\n",
    "            for point in points:\n",
    "                if point < len(face_landmarks.landmark):  # Verificar índice válido\n",
    "                    x = int(face_landmarks.landmark[point].x * frame.shape[1])\n",
    "                    y = int(face_landmarks.landmark[point].y * frame.shape[0])\n",
    "                    keypoints.append((x, y))  # Agregar las coordenadas a la lista\n",
    "            if (mode == 2):\n",
    "                apply_hat(frame, face_landmarks)\n",
    "                \n",
    "                # Calcular la distancia entre el labio superior e inferior (usando los puntos 13, 14, 18, 19)\n",
    "                lip_top = (int(face_landmarks.landmark[13].x * frame.shape[1]), int(face_landmarks.landmark[14].y * frame.shape[0]))\n",
    "                lip_bottom = (int(face_landmarks.landmark[18].x * frame.shape[1]), int(face_landmarks.landmark[19].y * frame.shape[0]))\n",
    "                draw_burgers(calculate_distance(lip_top, lip_bottom), lip_top, frame)\n",
    "    \n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Filtro Modo Duende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos las mallas de media pipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Cargar las imágenes de las orejas\n",
    "left_ear_img = cv2.imread('images/orejaI.png', cv2.IMREAD_UNCHANGED) \n",
    "right_ear_img = cv2.imread('images/orejaD.png', cv2.IMREAD_UNCHANGED)\n",
    "emoji_img = cv2.imread('images/dinero.png', cv2.IMREAD_UNCHANGED) \n",
    "\n",
    "# Lista para almacenar los emojis de dinero\n",
    "falling_emoji = []\n",
    "\n",
    "# Clase para el dinero que cae\n",
    "class FallingEmoji:\n",
    "    def __init__(self, x, y, speed, time_to_live):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.speed = speed\n",
    "        self.time_to_live = time_to_live  # Tiempo de vida del emoji\n",
    "        self.creation_time = time.time()  # Momento en que se creó el emoji\n",
    "\n",
    "    def update(self):\n",
    "        self.y += self.speed  # Movimiento hacia abajo\n",
    "        if self.y > 480:  # Si el emoji se sale de la pantalla, lo reubicamos en la parte superior\n",
    "            self.y = 0\n",
    "            self.x = random.randint(0, 640)\n",
    "\n",
    "        # Verificar si el emoji ha excedido su tiempo de vida\n",
    "        if time.time() - self.creation_time > self.time_to_live:\n",
    "            return False  \n",
    "        return True \n",
    "    \n",
    "def euclidean_distance(p1, p2):\n",
    "    return math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)\n",
    "\n",
    "def process_frame_mode1(frame, face_mesh):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    points_data = {}\n",
    "\n",
    "    if results.multi_face_landmarks is not None:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            points = [234, 454, 0, 17]  # Añadimos los puntos para las orejas (234 y 454) y los puntos de la boca (0 y 17)\n",
    "\n",
    "            for point in points:\n",
    "                if point < len(face_landmarks.landmark):\n",
    "                    x = face_landmarks.landmark[point].x\n",
    "                    y = face_landmarks.landmark[point].y\n",
    "                    z = face_landmarks.landmark[point].z\n",
    "\n",
    "                    x_pixel = int(x * frame.shape[1])\n",
    "                    y_pixel = int(y * frame.shape[0])\n",
    "\n",
    "                    points_data[point] = {'x': x_pixel, 'y': y_pixel, 'z': z}\n",
    "\n",
    "            # Colocamos las orejas (puntos 234 y 454 para la oreja izquierda y derecha)\n",
    "            if 234 in points_data:\n",
    "                left_ear_position = points_data[234]\n",
    "                left_ear_resized = cv2.resize(left_ear_img, (100, 100))  # Aumentamos el tamaño de la oreja\n",
    "                lx, ly = left_ear_position['x'], left_ear_position['y']\n",
    "\n",
    "                # Ajustamos vertical y horizontalmente\n",
    "                lx -= 80  \n",
    "                ly -= 60 \n",
    "\n",
    "                # Aseguramos de que la oreja no se salga de los limites\n",
    "                if lx + left_ear_resized.shape[1] > frame.shape[1]:\n",
    "                    lx = frame.shape[1] - left_ear_resized.shape[1]\n",
    "                if ly + left_ear_resized.shape[0] > frame.shape[0]:\n",
    "                    ly = frame.shape[0] - left_ear_resized.shape[0]\n",
    "\n",
    "                # Superponemos la oreja izquierda en el frame\n",
    "                for c in range(0, 3):  # Para las 3 capas (RGB)\n",
    "                    if lx + left_ear_resized.shape[1] <= frame.shape[1] and ly + left_ear_resized.shape[0] <= frame.shape[0]:\n",
    "                        frame[ly:ly + left_ear_resized.shape[0], lx:lx + left_ear_resized.shape[1], c] = \\\n",
    "                            left_ear_resized[:, :, c] * (left_ear_resized[:, :, 3] / 255.0) + \\\n",
    "                            frame[ly:ly + left_ear_resized.shape[0], lx:lx + left_ear_resized.shape[1], c] * (1.0 - left_ear_resized[:, :, 3] / 255.0)\n",
    "\n",
    "            if 454 in points_data:\n",
    "                right_ear_position = points_data[454]\n",
    "                right_ear_resized = cv2.resize(right_ear_img, (100, 100))  # Aumentamos el tamaño de la oreja\n",
    "                rx, ry = right_ear_position['x'], right_ear_position['y']\n",
    "\n",
    "                # ajustamos la oreja al rosto\n",
    "                rx -= 15  \n",
    "                ry -= 60 \n",
    "\n",
    "                # Aseguramos de que la oreja no se salga\n",
    "                if rx + right_ear_resized.shape[1] > frame.shape[1]:\n",
    "                    rx = frame.shape[1] - right_ear_resized.shape[1]\n",
    "                if ry + right_ear_resized.shape[0] > frame.shape[0]:\n",
    "                    ry = frame.shape[0] - right_ear_resized.shape[0]\n",
    "\n",
    "                # Superponer la oreja derecha en el frame\n",
    "                for c in range(0, 3):  # Para las 3 capas (RGB)\n",
    "                    if rx + right_ear_resized.shape[1] <= frame.shape[1] and ry + right_ear_resized.shape[0] <= frame.shape[0]:\n",
    "                        frame[ry:ry + right_ear_resized.shape[0], rx:rx + right_ear_resized.shape[1], c] = \\\n",
    "                            right_ear_resized[:, :, c] * (right_ear_resized[:, :, 3] / 255.0) + \\\n",
    "                            frame[ry:ry + right_ear_resized.shape[0], rx:rx + right_ear_resized.shape[1], c] * (1.0 - right_ear_resized[:, :, 3] / 255.0)\n",
    "\n",
    "            # Calcular la distancia entre los puntos 0 y 17 para saber si la boca está abierta\n",
    "            if 0 in points_data and 17 in points_data:\n",
    "                mouth_open_distance = euclidean_distance(\n",
    "                    (points_data[0]['x'], points_data[0]['y']),\n",
    "                    (points_data[17]['x'], points_data[17]['y'])\n",
    "                )\n",
    "\n",
    "                # Umbral para la distancia \n",
    "                threshold = 40 \n",
    "\n",
    "                probabilidad_generar_emoji = 0.1\n",
    "\n",
    "                if mouth_open_distance > threshold and random.random() < probabilidad_generar_emoji:\n",
    "                    if random.random() < 0.4:\n",
    "                        new_emoji = FallingEmoji(random.randint(0, frame.shape[1] - 80), 0, random.randint(2, 5), time_to_live=5)\n",
    "                        falling_emoji.append(new_emoji)\n",
    "                                \n",
    "                # Eliminamos segun va pasando el tiempo de vida\n",
    "                falling_emoji[:] = [emoji for emoji in falling_emoji if emoji.update()]\n",
    "            \n",
    "\n",
    "            # Actualizamos la posición de los emojis que caen\n",
    "            for emoji in falling_emoji:\n",
    "                emoji.update()\n",
    "                # Redimensionamos la imagen del emoji\n",
    "                emoji_resized = cv2.resize(emoji_img, (80, 50))\n",
    "\n",
    "                # Superponemos el emoji sobre el frame\n",
    "                for c in range(0, 3):\n",
    "                    if emoji.y + emoji_resized.shape[0] <= frame.shape[0] and emoji.x + emoji_resized.shape[1] <= frame.shape[1]:\n",
    "                        frame[emoji.y:emoji.y + emoji_resized.shape[0], emoji.x:emoji.x + emoji_resized.shape[1], c] = \\\n",
    "                            emoji_resized[:, :, c] * (emoji_resized[:, :, 3] / 255.0) + \\\n",
    "                            frame[emoji.y:emoji.y + emoji_resized.shape[0], emoji.x:emoji.x + emoji_resized.shape[1], c] * (1.0 - emoji_resized[:, :, 3] / 255.0)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de cambio de pelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gatete\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\mediapipe\\tasks\\python\\vision\\image_segmenter.py:158: UserWarning: MessageFactory class is deprecated. Please use GetMessageClass() instead of MessageFactory.GetPrototype. MessageFactory class will be removed after 2024.\n",
      "  graph_config = self._runner.get_graph_config()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks.python import BaseOptions\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Configuración del ImageSegmenter (para segmentación de cabello)\n",
    "options = vision.ImageSegmenterOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"models/hair_segmenter.tflite\"),\n",
    "    output_category_mask=True,\n",
    "    running_mode=vision.RunningMode.LIVE_STREAM,\n",
    "    result_callback=lambda result, output_image, timestamp_ms: setattr(SEGMENTER, 'last_result', result)\n",
    ")\n",
    "SEGMENTER = vision.ImageSegmenter.create_from_options(options)\n",
    "\n",
    "def apply_hair_segmentation_filter(frame):\n",
    "    # Reducción de resolución para mejorar la velocidad de procesamiento\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    frame_rgb = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "    prev_time = 0\n",
    "    fps_limit = 15  # Limitar a 15 FPS para procesamiento\n",
    "\n",
    "    # Control de FPS\n",
    "    current_time = time.time()\n",
    "    if (current_time - prev_time) * 1000 >= (1000 / fps_limit):\n",
    "        SEGMENTER.segment_async(frame_rgb, time.time_ns() // 1_000_000)\n",
    "        prev_time = current_time\n",
    "\n",
    "    # Procesar y mostrar resultados si existen\n",
    "    if hasattr(SEGMENTER, 'last_result') and SEGMENTER.last_result:\n",
    "        segmentation_result = SEGMENTER.last_result\n",
    "        category_mask = segmentation_result.category_mask.numpy_view()\n",
    "\n",
    "        # Crear una máscara de color solo en la región de cabello (color morado)\n",
    "        hair_color = (255, 0, 255)  # Morado en BGR\n",
    "        color_mask = np.zeros_like(frame_resized)\n",
    "        color_mask[category_mask == 1] = hair_color\n",
    "\n",
    "        # Aplicar desenfoque a la máscara para suavizar los bordes\n",
    "        blurred_mask = cv2.GaussianBlur(color_mask, (15, 15), 0)\n",
    "\n",
    "        # Mezclar la imagen original con la máscara de color para resaltar el cabello\n",
    "        final_frame = cv2.addWeighted(frame_resized, 1, blurred_mask, 0.4, 0)\n",
    "\n",
    "        return final_frame\n",
    "    else:\n",
    "        return frame_resized  # Si no hay resultados, devolver el frame original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_filtro(frame, mode, points):\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            min_detection_confidence=0.5) as face_mesh:\n",
    "        if mode == 1:\n",
    "            frame = process_frame_mode1(frame, face_mesh)\n",
    "        elif mode == 2:        \n",
    "            process_frame(frame, face_mesh, points, mode)\n",
    "        return\n",
    "\n",
    "def change_filter(frame, mode):\n",
    "    if mode == 1: aplicar_filtro(frame, mode, [0, 17, 468, 473])\n",
    "    elif mode == 2: aplicar_filtro(frame, mode, [127, 356, 183, 332])\n",
    "    return\n",
    "\n",
    "# Función principal\n",
    "def main(): \n",
    "    cap = cv2.VideoCapture(0) \n",
    "    mode = 1  # Modo inicial\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "            \n",
    "    if not cap.isOpened():\n",
    "        print(\"No se puede abrir la cámara\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Cambiar filtro según el modo\n",
    "        if mode != 3: change_filter(frame, mode)\n",
    "        elif mode == 3: frame = apply_hair_segmentation_filter(frame)\n",
    "        \n",
    "        # Mostramos el frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('1'): mode = 1\n",
    "        elif key == ord('2'): mode = 2\n",
    "        elif key == ord('3'): mode = 3\n",
    "        elif key == ord('q'):  break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
